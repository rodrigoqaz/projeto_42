{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "datascience_lab.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX0wXJpURTuc",
        "colab_type": "text"
      },
      "source": [
        "# Mão na massa!!!\n",
        "\n",
        "Vamos construir um modelo de classificação, baseado no desafio Kaggle [\"Titanic: Machine Learning from Disaster”](https://www.kaggle.com/c/titanic/data). Esse modelo de classificação terá como objetivo prever quais passageiros sobreviveram ao naufrágio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiUjAcmIRtUP",
        "colab_type": "text"
      },
      "source": [
        "**Fase 1 - Identificação do problema de negócio:**\n",
        "\n",
        "Aqui a gente vai identificar os dados disponíveis, qual sua estrutura e como vamos utilizar para a nossa análise. O Kaggle já disponibiliza os [dados](https://www.kaggle.com/c/titanic/data) rotulados para constriução do modelo e um dado de teste para submeter na competição .\n",
        "\n",
        "Nesta atividade a gente vai usar apenas a base para construção do modelo. \n",
        "\n",
        "Na célula abaixo podemos ver como importar o conjunto de dados para a variavel 'dados':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJCVOMu5VBiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Importa base de dados:\n",
        "uri = 'https://drive.google.com/u/0/uc?id=1OL3yv6CdvSsgLaCwuNQtGA-Ku1GAEOpV&export=download'\n",
        "dados = pd.read_csv(uri)\n",
        "dados.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYce7uRTbK6l",
        "colab_type": "text"
      },
      "source": [
        "**Fase 2 - Análise exploratória e preparação dos dados**\n",
        "\n",
        "Nessa parte a gente vai fazer algumas estatísticas e limpeza da nossa base de dados.\n",
        "\n",
        "O primeiro passo é ter uma visão geral de como os dados estão se comportando:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6Go49chbsoe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Análise estatistica descritiva - variáveis numéricas\n",
        "dados.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akaJSxRRdl9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Análise estatistica descritiva - variáveis categóricas\n",
        "dados.describe(include=['O'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZptaB8xec-B",
        "colab_type": "text"
      },
      "source": [
        "Ainda nessa fase, o próximo passo é a limpeza dos dados. Vamos remover alguns atributos e registros que não são relevantes para a análise, assim como codificar as variáveis textuais em números."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sPULd_uip03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remover atributos irrelevantes \n",
        "atributos_irrelevantes = ['Name', 'Ticket', 'Cabin', 'PassengerId']\n",
        "dados = dados.drop(atributos_irrelevantes, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI-prec1grBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove registros nulos\n",
        "dados = dados.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiMJ3GqmoFZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Codifica as variáveis string para numérico\n",
        "\n",
        "dados['Sex'] = dados['Sex'].map({'female':1, 'male':0})\n",
        "dados['Embarked'] = dados['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
        "\n",
        "dados.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUUgYSwLrUgh",
        "colab_type": "text"
      },
      "source": [
        "Por fim, a última etapa desta fase é segmentar a base de dados em \"treinamento\" e \"validação\":\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_6nh0mArdQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.model_selection\n",
        "treinamento, validacao = sklearn.model_selection.train_test_split(dados, random_state=1)\n",
        "treinamento.shape, validacao.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ftapOfNr4WM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Separa as features do target:\n",
        "\n",
        "treinamento_x = treinamento.drop('Survived', axis=1)\n",
        "treinamento_y = treinamento['Survived']\n",
        "validacao_x = validacao.drop('Survived', axis=1)\n",
        "validacao_y = validacao['Survived']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srMCYHoIbtYv",
        "colab_type": "text"
      },
      "source": [
        "**Fase 3 - Criação e otimização de modelos**\n",
        "\n",
        "Nessa fase, com os dados já estruturados, o próximo passo que devemos tomar é a criação dos modelos de previsão. Neste exemplo vamos treinar dois modelos:\n",
        "\n",
        "\n",
        "1.   Regressão Logística\n",
        "2.   Rede Neural\n",
        "\n",
        "Abaixo o código para o treinamento para o modelo de regressão:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHKgWPWTsbxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Modelo construido com o scikit-learn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "modelo_reglog = LogisticRegression(solver='liblinear')\n",
        "modelo_reglog.fit(treinamento_x, treinamento_y)\n",
        "acc_reglog = round( modelo_reglog.score(treinamento_x, treinamento_y) * 100, 2)\n",
        "print ('Acurácia: ' + str(acc_reglog) + '%')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olOenTYGt4ur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testando o modelo na base de validação:\n",
        "acc_reglog = round( modelo_reglog.score(validacao_x, validacao_y) * 100, 2)\n",
        "print ('Acurácia: ' + str(acc_reglog) + '%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWeJqGQsyxY7",
        "colab_type": "text"
      },
      "source": [
        "Abaixo o treinamento da rede neural:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSMb-393uzei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#modelo construido com o tensorflow\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(7, activation=tf.nn.relu, input_shape=[7]),\n",
        "  tf.keras.layers.Dense(14, activation=tf.nn.softmax),\n",
        "  tf.keras.layers.Dense(196, activation=tf.nn.softmax),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(2, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uecPctc5u7oA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(treinamento_x, treinamento_y, epochs=200)\n",
        "model.evaluate(validacao_x, validacao_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnwDsyfWbu-Y",
        "colab_type": "text"
      },
      "source": [
        "**Fase 4 - Implantação do modelo**\n",
        "\n",
        "Por fim, a última etapa, é a aplicação no modelo na base. Para isso, devemos atentar para que os dados de saída sejam no mesmo formato que os dados de origem, no caso, binário (\"0\" se morreu e \"1\"se sobreviveu)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m12cN20kws8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "previsoes = model.predict(validacao_x)\n",
        "previsoes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M76Ijp42xPdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "previsoes_bin=[]\n",
        "for i in previsoes[:,1]:\n",
        "    if i > 0.5:\n",
        "        previsoes_bin.append(1)\n",
        "    else:\n",
        "        previsoes_bin.append(0)\n",
        "previsoes_bin"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}